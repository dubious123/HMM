#LSTM 패키지 설치
pip install tensorflow numpy pandas scikit-learn matplotlib

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

# 시계열 데이터 예제 생성 (sin 함수 활용)
def create_time_series(n=1000):
    x = np.linspace(0, 100, n)
    y = np.sin(x) + np.random.normal(scale=0.1, size=n)  # 약간의 노이즈 추가
    return y

data = create_time_series()

# 데이터 시각화
plt.plot(data)
plt.title("Generated Time Series Data")
plt.show()

# 데이터 정규화
scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data.reshape(-1, 1))

# 시퀀스 데이터 생성
def create_sequences(data, seq_length):
    sequences, labels = [], []
    for i in range(len(data) - seq_length):
        sequences.append(data[i:i+seq_length])
        labels.append(data[i+seq_length])
    return np.array(sequences), np.array(labels)

SEQ_LENGTH = 10  # 시퀀스 길이 (입력값의 개수)
X, y = create_sequences(data_scaled, SEQ_LENGTH)

# 훈련/테스트 데이터 분리
# 이 예시에서는 데이터의 80%를 훈련용, 나머지 20%를 테스트용으로 설정한 것
# 시계열 데이터는 시간 순서를 유지해야 함

split = int(len(X) * 0.8)
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

# 입력 형태 변환 (LSTM 입력 형태로)
# LSTM은 3D 텐서 형태의 데이터를 입력으로 받음
# (samples, timesteps, features)
# samples : 총 입력 데이터의 개수 (훈련 데이터셋의 샘플 개수)
# timesteps : 하나의 샘플이 포함하는 시간 스텝 (시퀀스 길이)
# features : 각 타임스텝에서의 특징(feature) 개수
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)
# reshape을 통해 각 시퀀스에 대해 특징 수 차원을 추가 한 것

# 만약 여러 개의 변수를 활용하고 싶다면 reshape 할 때 feature 수를 N으로 설정

# LSTM 모델 구축
model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(SEQ_LENGTH, 1)),  # 첫 번째 LSTM 층
    LSTM(50, return_sequences=False),  # 두 번째 LSTM 층 - 마지막 시점만 출력만 사용
    Dense(25),  # 완전 연결층
    Dense(1)  # 출력층 - 최종 예측값
])

# sequential() : 순차적 모델을 의미함 - 추가하는 각 층이 앞 층의 출력을 다음 층의 입력으로 순차적으로 전달하는 구조
# 첫 번째 LSTM 층은 셀 50개를 갖는다는 것. 50개의 뉴런이 있고, 각각 시계열 데이터 학습
# return_sequences = True : 모든 타임스텝에서 출력을 반환한다는 것. 각 시점에서의 LSTM 출력을 다음 LSTM 층으로 보낸다는 것
# input_shape=(SEQ_LENGTH, 1) : 입력 데이터 형태 지정. 

# 모델 컴파일 및 학습
model.compile(optimizer='adam', loss='mse')
# adam : 최적화 알고리즘 Adaptive Moment Estimation으로, 딥러닝에서 가장 많이 사용되는 최적화 알고리즘
# mse : 손실 함수, 평균제곱차 mean squared error, 회귀 문제에서 가장 많이 사용되는 손실 함수
model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test))
# epochs : 전체 데이터셋을 몇 번 반복해서 학습할 것인지 - 적절한 에포크 값을 찾기 위해서는 validation_loss를 모니터링하거나 earlyStopping을 사용해서 적절한 시점에서 자동으로 학습 중단하라고 함
# batch_size : 한 번의 학습에서 사용할 샘플 개수 , 여기에서는 16개의 데이터를 한번에 학습한 후 가중치를 업데이트
# validation_data : 검증 데이터로 학습 성능을 평가

# 모델 예측
y_pred = model.predict(X_test)

# 결과 역정규화
y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))
y_pred_inv = scaler.inverse_transform(y_pred)

# 예측 결과 시각화
plt.figure(figsize=(10, 5))
plt.plot(y_test_inv, label='Actual Data')
plt.plot(y_pred_inv, label='Predicted Data')
plt.legend()
plt.title("LSTM Time Series Prediction")
plt.show()


